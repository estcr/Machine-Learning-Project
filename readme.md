# üß† Predicci√≥n de Accidentes Cerebrovasculares

Este proyecto tiene como objetivo predecir la probabilidad de que un paciente sufra un accidente cerebrovascular utilizando varios algoritmos de Machine Learning y t√©cnicas de balanceo de clases.

## üìä Descripci√≥n del Proyecto

El principal desaf√≠o de este proyecto fue el desbalanceo de clases, ya que los casos de accidentes cerebrovasculares (Stroke) eran significativamente menores en comparaci√≥n con los casos negativos. Para abordar este problema, utilizamos t√©cnicas de balanceo de clases como SMOTE y Oversampling.

## üßπ Limpieza de Datos

La limpieza de datos es un paso crucial en cualquier proyecto de Machine Learning. En este proyecto, realizamos las siguientes tareas de limpieza de datos:

1. **Manejo de Valores Nulos**: Imputamos valores nulos en las columnas `bmi` y `smoking_status` utilizando la mediana y la moda, respectivamente.
2. **Codificaci√≥n de Variables Categ√≥ricas**: Convertimos variables categ√≥ricas como `gender`, `ever_married`, `work_type`, `Residence_type` y `smoking_status` en variables dummy utilizando `pd.get_dummies()`.
3. **Normalizaci√≥n de Datos**: Normalizamos las caracter√≠sticas num√©ricas como `age`, `avg_glucose_level` y `bmi` para asegurar que todas las caracter√≠sticas est√©n en la misma escala.

## üöÄ Algoritmos Evaluados

Evaluamos varios algoritmos de Machine Learning, incluyendo:

- **Random Forest**
- **XGBoost**
- **K-Nearest Neighbors (KNN)**
- **Regresi√≥n Log√≠stica**

## ‚öñÔ∏è T√©cnicas de Balanceo de Clases

Para mejorar la predicci√≥n de la clase minoritaria (Stroke), utilizamos las siguientes t√©cnicas de balanceo de clases:

- **SMOTE (Synthetic Minority Over-sampling Technique)**
- **Oversampling**

## üìà Resultados Generales

A pesar de nuestros esfuerzos, los modelos no mostraron consistencia en la predicci√≥n de la clase minoritaria. La precisi√≥n y el recall para la clase minoritaria siguieron siendo bajos.

### An√°lisis de los Modelos

| Modelo                                | Accuracy | Precision | Recall | F1-Score |
|---------------------------------------|----------|-----------|--------|----------|
| KNN (Oversampling)                    | 0.916830 | 0.111111  | 0.10   | 0.105263 |
| Random Forest (Oversampling)          | 0.942270 | 0.000000  | 0.00   | 0.000000 |
| XGBoost (Oversampling)                | 0.926614 | 0.142857  | 0.10   | 0.117647 |
| Decision Tree (Oversampling)          | 0.911937 | 0.166667  | 0.20   | 0.181818 |
| Logistic Regression (Oversampling)    | 0.721135 | 0.126984  | 0.80   | 0.219178 |
| KNN (SMOTE)                           | 0.886497 | 0.107143  | 0.18   | 0.134328 |
| Random Forest (SMOTE)                 | 0.913894 | 0.120000  | 0.12   | 0.120000 |
| XGBoost (SMOTE)                       | 0.920744 | 0.170213  | 0.16   | 0.164948 |
| Decision Tree (SMOTE)                 | 0.877691 | 0.087912  | 0.16   | 0.113475 |
| Logistic Regression (SMOTE)           | 0.844423 | 0.165644  | 0.54   | 0.253521 |

## üèÜ Mejor Modelo

El modelo **Logistic Regression (SMOTE)** fue seleccionado como el mejor modelo debido a su balance entre precisi√≥n, recall y F1-Score. Aunque su precisi√≥n general es m√°s baja, su alto recall y F1-Score lo hacen m√°s efectivo para identificar la clase minoritaria (Stroke).

## üì¶ Preparaci√≥n del Modelo para Despliegue

El modelo entrenado se ha guardado en un archivo `logistic_regression_smote_model.pkl` utilizando la biblioteca `joblib`. Este archivo puede ser cargado y utilizado para realizar predicciones en un entorno de producci√≥n.

## üîç Conclusiones

Aunque los modelos evaluados tienen un buen rendimiento general, su capacidad para predecir la clase minoritaria (Stroke) fue limitada. Esto se refleja en la baja precisi√≥n, recall y F1-score para la clase 1 (Stroke) en todos los modelos evaluados.

## üìÖ Pr√≥ximos Pasos

Para mejorar el rendimiento en la clase minoritaria, se pueden considerar las siguientes estrategias:

- **Ajustar el umbral de decisi√≥n**: Modificar el umbral de probabilidad para clasificar una instancia como clase 1.
- **T√©cnicas de balanceo de clases adicionales**: Explorar t√©cnicas como SMOTE combinado con Tomek Links o SMOTEENN para generar m√°s ejemplos sint√©ticos de la clase minoritaria y eliminar ejemplos ruidosos.
- **Modelos m√°s avanzados**: Probar modelos m√°s avanzados como redes neuronales profundas o ensamblajes de modelos.

En resumen, aunque los modelos evaluados tienen un buen rendimiento general, es necesario abordar el desbalanceo de clases para mejorar la predicci√≥n de la clase minoritaria (Stroke). Debido a esta falta de consistencia en la predicci√≥n de la clase minoritaria, no recomendamos continuar con este proyecto ni llevarlo a producci√≥n en su estado actual. Sin embargo, continuaremos trabajando en este proyecto con fines educativos, explorando nuevas t√©cnicas y enfoques para mejorar el rendimiento de los modelos.

## üìö Recursos

- [Documentaci√≥n de Scikit-Learn](https://scikit-learn.org/stable/documentation.html)
- [Documentaci√≥n de Imbalanced-Learn](https://imbalanced-learn.org/stable/)
- [Documentaci√≥n de Joblib](https://joblib.readthedocs.io/en/latest/)

## ‚ú® Contribuciones

¬°Las contribuciones son bienvenidas! Si tienes alguna idea o mejora, no dudes en abrir un issue o enviar un pull request.

## üë®‚Äçüíº Autor

- Esteban Cristos Muzzupappa - [LinkedIn](https://www¬∑linkedin¬∑com/in/esteban-cristos-muzzupappa/)
- Gerardo Jimenez - [LinkedIn](https://www¬∑linkedin¬∑com/in/gerardo-jimenez/) 


üëã **Gracias por visitar este proyecto!** Si tienes preguntas o sugerencias, no dudes en abrir un issue o contactarnos directamente.